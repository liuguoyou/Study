{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table: **\n",
    "Methods to reduce numerical precison for AlexNet. Accuracy measured for Top-5 error on ImageNet. * Not Applied to first and/or last layers\n",
    "![](2016_methods_to_reduce_numerical_precision_for_AlexNet.png)\n",
    "\n",
    "source: [Efficient Processing of Deep Neural Networks: A Tutorial and Survey](https://arxiv.org/abs/1703.09039)\n",
    " on page 22\n",
    "\n",
    "**Method**:\n",
    "\n",
    "binary/ternary weights: BC(BianryConnect), TC(TernaryConnect), TWN(Ternary Weight Networks), BWN(Binary Weight Networks)\n",
    "\n",
    "binary/ternary weights and binary/ternary activatons: BNN(Binarized Neural Networks), XNOR-Nets\n",
    "\n",
    "n-bit quantization for weights, activations, gradients: DoReFa-Net, QNN(Quantized Neural Networks), \n",
    "\n",
    "Bitwise NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## BNNs\n",
    "\n",
    "### Article\n",
    "[Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1](https://arxiv.org/abs/1602.02830)\n",
    "\n",
    "### Author\n",
    "- Matthieu Courbariaux\n",
    "- Itay Hubara\n",
    "- Daniel Soudry\n",
    "- Ran El-Yaniv\n",
    "- Yoshua Bengio\n",
    "\n",
    "### Time\n",
    "2016.2\n",
    "### Method\n",
    "Binary/Ternary\n",
    "### Ideas/Contributions\n",
    "Binarization method: deterministic (b = sign(x)) (uesd) or stochastic(b 依概率$p = \\sigma(x) = \\mathrm{clip}(\\frac{x+1}{2}, 0, 1)$为+1， otherwise -1)\n",
    "\n",
    "Binarized activations+weights, during training and test\n",
    "\n",
    "Gradients propagating method: straight-through estimator\n",
    "$$q = \\mathrm{sign}(r)$$\n",
    "$$g _ r = g _ q \\mathbb{1}_{|r| \\leq 1}$$\n",
    "\n",
    "First layer: 8bit images compute 8 times, then mutiply $2^i$ and sum.\n",
    "$$s = x \\cdot w^b$$\n",
    "$$s = \\sum_{n=1}^{8}{2^{n-1}(x^n \\cdot w^b)}$$\n",
    "\n",
    "Weight clipping: (Update) $W \\leftarrow \\mathrm{clip}(W, -1, 1)$\n",
    "\n",
    "Others: Shift based Batch Normalizing Transform(使用移位运算的Batch Norm)\n",
    "\n",
    "Others: Shift based AdaMax\n",
    "\n",
    "Training: Inputs(R), Weights({-1, 1}), Activations({-1, 1})  \n",
    "Deployment: Inputs(R), Weights({-1, 1}), Activations({-1, 1}) \n",
    "\n",
    "### Experiments\n",
    "\n",
    "Classification test error rates\n",
    "\n",
    "| MNIST | SVHN | CIFAR-10 | ImageNet\n",
    "--|--|-----------\n",
    "BNNs | 1.40% | 2.53% | 10.15%| -\n",
    "\n",
    "### Other Results\n",
    "Assuming we have $M_l$ filters in the $l$ convolutional layer, we have to store a 4D weight matrix of size $M_l \\times M_{l-1} \\times k \\times k$. Consequently, the number of unique filters is $2^{k^2 M_{l-1}}$\n",
    "\n",
    "\n",
    "For example, in our ConvNet architecture trained on the CIFAR-10 benchmark, there are only 42% unique filters per layer on average.\n",
    "\n",
    "Seven Times Faster on GPU at Run-Time\n",
    "\n",
    "In comparison with 32-bit DNNs, BNNs require 32 times smaller memory size and 32 times fewer memory accesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNNs(tune, ImageNet)\n",
    "\n",
    "### Article\n",
    "\n",
    "Binarized Neural Networks on the ImageNet Classification Task\n",
    "\n",
    "### Author\n",
    "\n",
    "- Xundong Wu\n",
    "- Yong Wu\n",
    "- Yong Zhao\n",
    "\n",
    "### Time\n",
    "2016.4\n",
    "\n",
    "### Method\n",
    "\n",
    "binary/ternary\n",
    "\n",
    "### Ideas/Contributions\n",
    "\n",
    "First Layer: regular weight convolutional layer\n",
    "\n",
    "Training: When we use a lower learning rate of 0.001, we observed a weight distribution more uniform or concentrated around 0, indicating the weights are taking more steps to travel between -1 and +1.\n",
    "\n",
    "dropout ratio of 0.2 was used for the dropout layer\n",
    "\n",
    "wider than usual layers used for the first and second layers, to avoid information bottleneck associated with binarized networks.\n",
    "\n",
    "### Experiments\n",
    "\n",
    "- 13 layer network trained with regular targets achieved 80% top-5 accuracy.\n",
    "- 13 layer network trained with soft targets. \n",
    "- Fine tuning the 13 layer network with combined soft and regular target achieved 84.1% top-5 accuracy\n",
    "\n",
    "With a moderate size network of 13 layers, we obtained top-5 classification accuracy rate of 84.1 percent on validation set through network distillation, much better than previous published results of 73.2% on XNOR network and 69.1% on binarized GoogleNET.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "## GXNOR networks\n",
    "\n",
    "**Article**: [Gated XNOR Networks: Deep Neural Networks with Ternary Weights and Activations under a Unified Discretization Framework](https://arxiv.org/abs/1705.09283)\n",
    "\n",
    "**Author**: Lei Deng, Peng Jiao, Jing Pei, Zhenzhi Wu, Guoqi Li\n",
    "\n",
    "**Time**: 2017.5\n",
    "\n",
    "**Method**: Binary/Ternary\n",
    "\n",
    "**Ideas/Contributions**:\n",
    "\n",
    "1. 权值和激活值都在$\\mathbb{Z}_N$离散数空间中，二值或三值是其特殊情况，\n",
    "2. 对于三值的量化函数给出新的梯度近似（不同与BNN或XNOR-NET）\n",
    "3. （discrete state transition，DST方法）基于概率实现权值的更新（即反向传播的为离散值，而非连续实数）\n",
    "4. “门控”电路，有利于硬件实现\n",
    "\n",
    "** Experiments**:\n",
    "\n",
    "三值化的GXNOR在MNIST，CIFAR-10，SVHN中的准确率达到顶尖水平\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "## LBC\n",
    "**未看**\n",
    "\n",
    "**Article**: [Local Binary Convolutional Neural Networks](https://arxiv.org/abs/1608.06049)\n",
    "\n",
    "**Author**: Felix Juefei-Xu, Vishnu Naresh Boddeti, Marios Savvides\n",
    "\n",
    "**Time**: 16.08\n",
    "\n",
    "** Method**: Compress\n",
    "\n",
    "**Ideas/Contributions**:\n",
    "\n",
    "Local binary patterns (LBP)\n",
    "\n",
    "**Experiments**:\n",
    "\n",
    "- 与常规CNN在MNIST，CIFAR-10,SVHN,ImageNet上保持了相近的准确率\n",
    "- 离散和二值化权重，减少9~169倍参数（取决于filter大小）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Low-Precision Batch-Normalized Activations](https://arxiv.org/abs/1702.08231)\n",
    "\n",
    "大致是替换Batch Normalizaed和ReLu为低精度版本以减少计算量和空间\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "**Article**:[Network Sketching: Exploiting Binary Structure in Deep CNNs](https://arxiv.org/abs/1706.02021)\n",
    "\n",
    "**Author**: Yiwen Guo, Anbang Yao, Hao Zhao, Yurong Chen\n",
    "\n",
    "**Time**: 2017.06\n",
    "\n",
    "**Method**: binary-weight CNNs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## TNNs\n",
    "\n",
    "**Article**: [Ternary Neural Networks for Resource-Efficient AI Applications](https://arxiv.org/abs/1609.00222)\n",
    "\n",
    "**Author**: Hande Alemdar, Vincent Leroy, Adrien Prost-Boucle, Frédéric Pétrot\n",
    "\n",
    "**Time**: 2016.09\n",
    "\n",
    "**Method**: Binary/Ternary\n",
    "\n",
    "**Ideas/Contributions**:\n",
    "\n",
    "Training: Inputs({-1, 0, 1}), Weights(R), Activations({-1, 0, 1})  \n",
    "Deployment: Inputs({-1, 0, 1}), Weights({-1, 0, 1}), Activations({-1, 0, 1})\n",
    "\n",
    "Fully Discretized(完全不用浮点运算和乘法操作(TEST))\n",
    "\n",
    "FGPA，ASIC硬件实现\n",
    "\n",
    "**Experiments**:\n",
    "\n",
    "|MNIST |CIFAR10 |SVHN |GTRSB| CIFAR100\n",
    "--|--|--\n",
    "TNNs | 1.67 | 12.11 | 2.73 | 0.98 | 48.40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## TNNs\n",
    "\n",
    "**Article**: [Ternary Neural Networks with Fine-Grained Quantization](https://arxiv.org/abs/1705.01462)\n",
    "\n",
    "**Author**: Naveen Mellempudi, Abhisek Kundu, Dheevatsa Mudigere, Dipankar Das, Bharat Kaul, Pradeep Dubey\n",
    "\n",
    "**Time**: 2017.05\n",
    "\n",
    "**Method**: Compress\n",
    "\n",
    "**Ideas/Contributions**:\n",
    "\n",
    "ternary weights, 8/4bit activations, with minimal or no re-training, and yet achieving near state-of-art accuracy.\n",
    "\n",
    "propose a novel fine-grained quantization (FGQ) method to convert pre-trained models to a ternary representation with minimal loss in test accuracy, without re-training.\n",
    "\n",
    "**Experiments**:\n",
    "\n",
    "achieve classification accuracy (Top-1) of 73.85% with 8-bit activations (2w-8a) and 70.69% with 4-bit activations (2w-4a), on the ImageNet dataset using a pre-trained Resnet-101 model (no re-training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## TWN\n",
    "\n",
    "**Article**: [Ternary weight networks](https://arxiv.org/abs/1605.04711)\n",
    "\n",
    "**Author**: Fengfu Li, Bo Zhang, Bin Liu\n",
    "\n",
    "**Time**: 2016.05\n",
    "\n",
    "**Method**: ternay-weight\n",
    "\n",
    "**Ideas/Contributions**:\n",
    "\n",
    "权重三值化，并有缩放因子\n",
    "\n",
    "**Experiments**:\n",
    "\n",
    "Validation accuracies (%). Results on ImageNet are with ResNet-18 / ResNet-18B.\n",
    "![Validation accuracies (%). Results on ImageNet are with ResNet-18 / ResNet-18B.](TWN_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## BFCN\n",
    "\n",
    "**Article**: [Training Bit Fully Convolutional Network for Fast Semantic Segmentation](https://arxiv.org/abs/1612.00212)\n",
    "\n",
    "**Author**: He Wen, Shuchang Zhou, Zhe Liang, Yuxiang Zhang, Dieqiao Feng, Xinyu Zhou, Cong Yao\n",
    "\n",
    "**Time**: 2016.12\n",
    "\n",
    "**Method**: quantization\n",
    "\n",
    "**Ideas/Contributions**:\n",
    "\n",
    "Apply on Semantic Segmentation: propose BFCN, an FCN that has low bit-width weights and activations, which is an extension to the combination of methods from Binarized Neural Network, XNOR-net and DoReFa-net.\n",
    "\n",
    "replace the convolutional filter in reconstruction with residual blocks to better suit the need of low bit-width network.\n",
    "\n",
    "propose a novel bit-width decay method to train BFCN with better performance.\n",
    "\n",
    "\n",
    "**Experiments**:\n",
    "\n",
    "network |VOC12| Cityscapes| speedup\n",
    "--|--|--\n",
    "32-bit FCN| 69.8% |62.1%| 1x\n",
    "2-bit BFCN | 67.0% | 60.3% | 4.1x\n",
    "1-2 BFCN | 62.8% | 57.4% | 7.8x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTQ\n",
    "**Article**: [Trained Ternary Quantization](https://arxiv.org/abs/1612.01064)\n",
    "\n",
    "**Authors**: Chenzhuo Zhu, Song Han, Huizi Mao, William J. Dally\n",
    "\n",
    "**Time**: 2016.12\n",
    "\n",
    "**Method**: ternary-weight\n",
    "\n",
    "**Ideas/Contributions**:\n",
    "\n",
    "三值化时正负缩放因子不同且可训练\n",
    "\n",
    "\n",
    "**Experiments**:\n",
    "\n",
    "Top1 and Top5 error rate of AlexNet on ImageNet:\n",
    "\n",
    "Error | Full precision | 1-bit (DoReFa) | 2-bit (TWN) | 2-bit (Ours)\n",
    "--|--|--\n",
    "Top1 | 42.8% | 46.1% | 45.5% | 42.5%\n",
    "Top5 | 19.7% | 23.7% | 23.2% | 20.3%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XNOR-Net\n",
    "**Article**: [XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks](https://arxiv.org/abs/1603.05279)\n",
    "\n",
    "**Authors**: Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, Ali Farhadi\n",
    "\n",
    "**Time**: 2016.03\n",
    "\n",
    "**Method**: binary-weight+binary\n",
    "\n",
    "**Ideas/Contributions**:\n",
    "\n",
    "在BinaryNets的基础上添加缩放因子 \n",
    "\n",
    "Binary-Weight-Networks 和 XNOR-NET两种结构\n",
    "\n",
    "B-A-C-P 结构\n",
    "\n",
    "**Experiments**:\n",
    "\n",
    "This results in 58× faster convolutional operations (in terms of number of the high precision operations) and 32× memory savings.\n",
    "\n",
    "BWN and XNOR-Net outperform BinaryConnect(BC) and BinaryNet(BNN) in all the epochs by large margin(∼17%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNN\n",
    "**Article**: [Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations](https://arxiv.org/abs/1609.07061)\n",
    "\n",
    "**Authors**: Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, Yoshua Bengio\n",
    "\n",
    "**Time**: 2016.09\n",
    "\n",
    "**Method**: Quantization\n",
    "\n",
    "**Ideds/Contributions**:\n",
    "\n",
    "在Binaried Neural Networks的基础上放宽，从binary变为quantization\n",
    "\n",
    "**Experiments**:\n",
    "\n",
    "![](QNN_experiments.png)\n",
    "\n",
    "More Experiments On RNN, On GoolgeNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
